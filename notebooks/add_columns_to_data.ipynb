{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Example on how to add data to the dataframe (database)\n",
    "\n",
    "Here we need to add new weather columns to the dataframe. Specifically:\n",
    "\n",
    "```python\n",
    "cols = [\n",
    "    \"precipitation\",\n",
    "    \"wind_gusts_10m\",\n",
    "    \"cloud_cover\",\n",
    "    'shortwave_radiation'\n",
    "]\n",
    "```\n",
    "\n",
    "This data can be obtained from the same API so the data collection is strigtforward. \n",
    "First, we update `variables_standard` in Openmeteo class to add new quantities. This will assure that they are downloaded for all future data updates. However they also need to be added to the dataframe itself. This can be accomplised as follows. "
   ],
   "id": "4a9d8a430edd019"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from glob import glob\n",
    "from scipy.stats import fisk_gen\n",
    "\n",
    "df_original = pd.read_parquet('../database/prev_latest.parquet')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_original.tail()",
   "id": "aa9c988e9211f00e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "start_date = pd.Timestamp(df_original.dropna(how='any',inplace=False).first_valid_index())\n",
    "today = pd.Timestamp(datetime.today())\n",
    "end_date = pd.Timestamp(df_original.dropna(how='any',inplace=False).last_valid_index())\n",
    "from data_modules.collect_data_openmeteo import get_weather_data_from_api_forecast, get_weather_data_from_api, \\\n",
    "    locations, OpenMeteo\n",
    "\n",
    "df_om_hist = get_weather_data_from_api(start_date, today-timedelta(hours=12), locations)\n",
    "\n"
   ],
   "id": "43cb84043aa03692",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_om_forecast = get_weather_data_from_api_forecast(locations=locations)\n",
    "if not df_om_forecast.columns.equals(df_om_hist.columns):\n",
    "    print(\"! Error. Column mismatch between historical and forecasted weather!\")\n",
    "df_om = pd.concat([df_om_hist, df_om_forecast[df_om_hist.columns]], ignore_index=True)\n",
    "df_om.drop_duplicates(subset='date', keep='last', inplace=True)\n",
    "# df_om = process_weather_quantities(df_om, locations)\n",
    "df_om.set_index('date',inplace=True)"
   ],
   "id": "59cfe965d696a60f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_om",
   "id": "356bda43387f3437",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# df_om.to_parquet('../database'+'db_openweather.parquet',engine='pyarrow')\n",
    "    "
   ],
   "id": "6dbf46b6210ce643",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from data_modules.collect_data_openmeteo import OpenMeteo\n",
    "for var in OpenMeteo.variables_standard:\n",
    "    for col in df_original.columns.to_list():\n",
    "        if str(col).__contains__(var):\n",
    "            df_original.drop(col, axis=1, inplace=True)"
   ],
   "id": "afebbe509d5afa74",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_original",
   "id": "580db36f5f8b15aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_original = df_original.join(df_om)",
   "id": "b46033c5233f8f94",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_original",
   "id": "4901d92506729f8f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5c810bab220da80d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Add SMARD columns",
   "id": "908af9bca939047c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "# df_original = pd.read_parquet('../database/latest.parquet')"
   ],
   "id": "c8bb52762ee2452",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_original",
   "id": "32e5045cbd865a7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "start_date = pd.Timestamp(df_original.dropna(how='any',inplace=False).first_valid_index())\n",
    "today = pd.Timestamp(datetime.today())\n",
    "end_date = pd.Timestamp(df_original.dropna(how='any',inplace=False).last_valid_index())"
   ],
   "id": "950981b89aac0977",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from data_modules.collect_data_smard import DataEnergySMARD\n",
    "o_smard = DataEnergySMARD(start_date=start_date, end_date=end_date)\n",
    "df_smard_flow = o_smard.get_international_flow()\n",
    "df_smard_flow"
   ],
   "id": "130ee42f43de7a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_smard_flow.set_index('date',inplace=True)",
   "id": "329f56b312b1d3ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "for col in df_smard_flow.columns.to_list():\n",
    "    if not col in df_original.columns.to_list():\n",
    "        print(f\"Adding...{col}\")\n",
    "        # merge the new column with the dataframe \n",
    "        df_original = df_original.merge(df_smard_flow[[col]], how='left', left_index=True, right_index=True)\n",
    "df_original.to_parquet('../database/latest.parquet')"
   ],
   "id": "e93934e88e65cdd9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "d",
   "id": "9dcb954faf74e5de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Add new SMARD data (after aggregation change) and split to history and forecast",
   "id": "df0e82017721eafa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_hist = pd.read_parquet('../database/history.parquet')\n",
    "last_ts = pd.Timestamp(df_hist.dropna(how='any',inplace=False).last_valid_index())+timedelta(hours=1)\n",
    "begin_ts = pd.Timestamp(df_hist.dropna(how='any',inplace=False).first_valid_index())\n",
    "print(last_ts, begin_ts)\n",
    "df_hist"
   ],
   "id": "3cfb8d74f83311ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from data_modules.collect_data_smard import DataEnergySMARD\n",
    "o_smard = DataEnergySMARD(start_date=begin_ts, end_date=last_ts)\n",
    "df_smard_flow = o_smard.get_international_flow()\n",
    "df_smard_gen_forecasted = o_smard.get_forecasted_generation()\n",
    "df_smard_con_forecasted = o_smard.get_forecasted_consumption()\n",
    "df_smard = pd.merge(left=df_smard_flow,right=df_smard_gen_forecasted,left_on='date',right_on='date',how='outer')\n",
    "df_smard = pd.merge(left=df_smard,right=df_smard_con_forecasted,left_on='date',right_on='date',how='outer')\n",
    "df_smard.set_index('date',inplace=True)"
   ],
   "id": "869ed7f7c687ad70",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# drop not needed cols from df_hist\n",
    "for col in df_hist.columns.to_list():\n",
    "    if col in df_smard.columns.to_list() and not col in ['DA_auction_price']:\n",
    "        df_hist.drop(col, axis=1, inplace=True)\n",
    "# drop cols that are not there but are no longer needed\n",
    "for col in df_hist.columns.to_list():\n",
    "    if col.__contains__('_flow'):\n",
    "        df_hist.drop(col, axis=1, inplace=True)\n",
    "# add cols from new data to old data\n",
    "for col in df_smard.columns.to_list():\n",
    "    df_hist[col] = df_smard[col]\n",
    "df_hist"
   ],
   "id": "42f86d0c6e90684e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_hist.to_parquet('../database/history.parquet')",
   "id": "17385294bebfe14f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e0b51e957070807c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Add EPEXSPOT DATA FROM FILES TO DATAFRAME ",
   "id": "cfee4b32d8fa7ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "from datetime import datetime, timedelta"
   ],
   "id": "df45c4e986961efa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_hist = pd.read_parquet('../database/history.parquet')\n",
    "last_ts = pd.Timestamp(df_hist.dropna(how='any',inplace=False).last_valid_index())+timedelta(hours=1)\n",
    "begin_ts = pd.Timestamp(df_hist.dropna(how='any',inplace=False).first_valid_index())\n",
    "print(last_ts, begin_ts)\n",
    "df_hist"
   ],
   "id": "6dc7e778ab7130f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "raw_datadir = \"../data/DE-LU/DayAhead_MRC/\"\n",
    "files = glob(raw_datadir + '*.csv')\n",
    "df_da_upd = pd.DataFrame()\n",
    "for file in files:\n",
    "    df_i = pd.read_csv(file)\n",
    "    df_da_upd = pd.concat([df_da_upd, df_i])\n",
    "if len(files) == 0:\n",
    "    raise FileNotFoundError(f\"File in {raw_datadir} does not exist\")\n",
    "df_da_upd['date'] = pd.to_datetime(df_da_upd['date'])\n",
    "df_da_upd.sort_values(by='date', inplace=True)\n",
    "df_da_upd.drop_duplicates(subset='date', keep='first', inplace=True)\n",
    "# for agreement with energy-charts\n",
    "df_da_upd['date'] = df_da_upd['date'].dt.tz_localize('Etc/GMT-2').dt.tz_convert('UTC') #\n",
    "df_da_upd.rename(columns={'Price':'DA_auction_price'},inplace=True)\n",
    "# we do not need other data for now\n",
    "df_da_upd = df_da_upd[['date','DA_auction_price']]\n",
    "df_da_upd.set_index('date',inplace=True)"
   ],
   "id": "d787ebb742263ac9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_hist = df_hist.fillna(df_da_upd)",
   "id": "6a64bc8d44383fbe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_hist\n",
   "id": "aa7b492c3b77e6e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_hist.to_parquet('../database/history.parquet')",
   "id": "b455aa707fbb6f7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5898a0c95ec0a681",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
